<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>NIU Metis Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="chapter_1.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="chapter_2.html"><strong aria-hidden="true">2.</strong> Basic Metis Usage</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="chapter_2_1.html"><strong aria-hidden="true">2.1.</strong> Building a C++ Project from the Ground Up</a></li><li class="chapter-item expanded "><a href="chapter_2_2.html"><strong aria-hidden="true">2.2.</strong> Building a CUDA Project from the Ground Up</a></li></ol></li><li class="chapter-item expanded "><a href="chapter_3.html"><strong aria-hidden="true">3.</strong> Intermediate Metis Usage with Docker</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="chapter_3_1.html"><strong aria-hidden="true">3.1.</strong> Using Pre-Made Docker Images</a></li><li class="chapter-item expanded "><a href="chapter_3_2.html"><strong aria-hidden="true">3.2.</strong> Using GPU Acceleration With Docker</a></li><li class="chapter-item expanded "><a href="chapter_3_3.html"><strong aria-hidden="true">3.3.</strong> Creating Your Own Docker Image</a></li></ol></li><li class="chapter-item expanded "><a href="chapter_4.html"><strong aria-hidden="true">4.</strong> Advanced Metis Usage Techniques</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="chapter_4_1.html"><strong aria-hidden="true">4.1.</strong> SSH Automation with Metis</a></li></ol></li><li class="chapter-item expanded "><a href="chapter_5.html"><strong aria-hidden="true">5.</strong> Conclusion and Helpful Resources</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">NIU Metis Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="1-introduction"><a class="header" href="#1-introduction">1. Introduction</a></h1>
<p>Welcome! This book serves as an all-in-one crash course in utilizing Metis, as well as some advanced techniques.</p>
<p>This documentation is not meant to replace NIU's documentation, but rather, to make it more beginner-friendly and to save you time!</p>
<p>While this book does assume a basic understanding of Linux and C++, it is not required.</p>
<p>If you have not logged into Metis before, or if it's been some time since you've used Linux, NIU CRCD has <a href="https://www.niu.edu/crcd/current-users/getting-started/login-to-metis.shtml">comprehensive documentation</a> on how to open a SSH connection, and a quick Linux refresher. If you would also like to refresh yourself on C++, w3schools has a wonderful <a href="https://www.w3schools.com/cpp/default.asp">quick reference</a> available.</p>
<p>Although this guide is about how to employ Docker on Metis, it does not assume you have previous experience with it, and includes a crash course on basic usage. The skills in that section provide tools to build even some of the most advanced applications, and also includes resources for those applications which require more.</p>
<p>For your convenience, every project example in this book can be found in <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects">the repository for this book</a>!</p>
<h2 id="primary-purpose"><a class="header" href="#primary-purpose">Primary Purpose</a></h2>
<p>The goal of this book is to allow researchers at NIU to hit the ground running with their research. Our goal is for you to focus less on getting Metis to work for you - and more on completing your work as a whole.</p>
<p>It's possible to create applications that will work regardless of what Metis has available to you for installation. Furthermore, you no longer have to develop directly on Metis - you can develop and build locally on hardware you're used to. This will allow you to focus on writing your application - without having to worry whether it can run on Metis.</p>
<p>We will do so by employing <a href="https://www.docker.com/">Docker</a>, an extremely powerful containerization and encapsulation tool that allows developers to define virtual machines with a level of granularity rarely found in modern computing. Docker allows you to select an operation system as a base, install packages and libraries, and define run behaviour.</p>
<p>All of this is defined in a singular, simple, and human-readable file that can be build to be reproduced on any system - including Metis.</p>
<h3 id="explored-use-cases"><a class="header" href="#explored-use-cases">Explored Use Cases</a></h3>
<p>There are five use cases covered here, with increasing levels of control over Metis:</p>
<ul>
<li><strong>Chapter 2.1 - Running a C++ project</strong>
<ul>
<li>No additional configuration</li>
<li>PBS only</li>
</ul>
</li>
<li><strong>Chapter 2.2 - Running a CUDA project</strong>
<ul>
<li>Loading CUDA via the <code>module</code> command</li>
<li>PBS only</li>
</ul>
</li>
<li><strong>Chapter 3.1 - Running a language not installed on Metis, such as Python 3.11</strong>
<ul>
<li>Downloading a pre-built Docker Image with <code>python</code> version 3.11 installed</li>
<li>PBS with Docker via Podman</li>
</ul>
</li>
<li><strong>Chapter 3.2 - Running packages not installed on Metis with GPU passthrough</strong>
<ul>
<li>Downloading a pre-built Docker Image</li>
<li>Passing through GPUs to Docker</li>
<li>PBS with Docker and NVIDIA Container Toolkit via Podman</li>
</ul>
</li>
<li><strong>Chapter 3.3 - Running virtually any project using custom Docker Images</strong>
<ul>
<li>Writing, building, and publishing your own Docker Image</li>
<li>Passing through GPUs to Docker</li>
<li>PBS with Docker and NVIDIA Container Toolkit via Podman</li>
</ul>
</li>
</ul>
<h3 id="advanced-techniques"><a class="header" href="#advanced-techniques">Advanced Techniques</a></h3>
<p>This guide will also explore one additional advanced technique:</p>
<ul>
<li><strong>Chapter 4.1 - SSH Automation</strong>
<ul>
<li>Demonstrates programmatic submission of PBS jobs via SSH for the purpose of fitting Metis into existing systems.</li>
</ul>
</li>
</ul>
<h2 id="where-do-i-need-to-read-to"><a class="header" href="#where-do-i-need-to-read-to">Where Do I Need to Read to?</a></h2>
<h3 id="cases-where-docker-may-not-be-needed"><a class="header" href="#cases-where-docker-may-not-be-needed">Cases Where Docker May Not Be Needed</a></h3>
<p>Check if your use case is either of the two below. If it is, you can safely stop reading after <strong>Chapter 2.2</strong>.</p>
<ul>
<li>Native C, Go, or Python applications with pre-existing or no dependencies</li>
<li>OpenMPI-based applications</li>
</ul>
<h3 id="cases-where-docker-is-needed"><a class="header" href="#cases-where-docker-is-needed">Cases Where Docker Is Needed</a></h3>
<p>If you only need CPU-based computation, you can safely stop reading after <strong>Chapter 3.1</strong>. If you need GPU passthrough or have a complicated project, it is recommended to read this book in its entirety!</p>
<ul>
<li>Applications with a language not listed above</li>
<li>Applications with dependencies Metis does not have encapsulated in its modulefiles</li>
<li>Applications with complex or circular dependencies</li>
<li>Applications which require a different operating system</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="2-basic-metis-usage"><a class="header" href="#2-basic-metis-usage">2. Basic Metis Usage</a></h1>
<p>This first chapter will provide two into-the-fire projects that will teach you the core systems of Metis. This will be done through a simple C++ project, followed by an optimized version written with CUDA.</p>
<p>These chapters lay the foundational skills needed to use the advanced techniques in the following chapters, and it is highly recommended that you read them before proceeding!</p>
<h2 id="overview-of-the-chapters"><a class="header" href="#overview-of-the-chapters">Overview of the Chapters</a></h2>
<h3 id="chapter-21-c-on-metis"><a class="header" href="#chapter-21-c-on-metis">Chapter 2.1: C++ on Metis</a></h3>
<ul>
<li><strong>Goals</strong>: Familiarize with basic commands and job submission on Metis.</li>
<li><strong>C++ Boilerplate</strong>: Create and run a basic "Hello, World" C++ program with computational loops.</li>
<li><strong>PBS Basics</strong>: Write a PBS job script to run your C++ program on compute nodes.</li>
<li><strong>Execution</strong>: Compile and run the C++ program locally and via PBS.</li>
<li><strong>Outcome</strong>: You will be able to understand job submission, the PBS script structure, and basic module commands.</li>
</ul>
<h3 id="chapter-22-building-a-cuda-project-from-the-ground-up"><a class="header" href="#chapter-22-building-a-cuda-project-from-the-ground-up">Chapter 2.2: Building a CUDA Project from the Ground Up</a></h3>
<ul>
<li><strong>Goals</strong>: Learn to use CUDA for GPU programming on Metis.</li>
<li><strong>CUDA Boilerplate</strong>: Write a CUDA program to achieve the same task as in Chapter 1.1 but using GPU acceleration.</li>
<li><strong>CUDA Modules</strong>: Install and use the CUDA compiler (nvcc) with module commands.</li>
<li><strong>Execution</strong>: Compile and run your CUDA program, observing performance improvements.</li>
<li><strong>PBS for CUDA</strong>: Adapt the PBS script to load CUDA modules and compile with nvcc.</li>
<li><strong>Outcome</strong>: You will be able to leverage CUDA for faster computation and understand the structure of both CUDA programs and PBS scripts.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="21-building-a-c-project-from-the-ground-up"><a class="header" href="#21-building-a-c-project-from-the-ground-up">2.1. Building a C++ Project from the Ground Up</a></h1>
<p><em>You can find the code mentioned in this chapter <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/cpp/cpp_on_metis">in this book's repository</a>!</em></p>
<p>This introductory project will teach you the absolute minimal nessecary information to create a basic C++ project on the Metis supercomputer.</p>
<p>Before we tackle more robust and complex technologies such as CUDA or OpenMPI, our goal is to familiarize ourselves with Metis before abstracting and building upon our understanding.</p>
<p>We'll instead opt to start with the most basic of programs - "Hello, World" (with, of course, a computationally intensive task) - to get started!</p>
<h2 id="goals"><a class="header" href="#goals">Goals</a></h2>
<ul>
<li>Get a feel for the <code>module</code> commands</li>
<li>Get a feel for the <a href="https://altair.com/pbs-professional">PBS Professional</a> job submission system</li>
<li>Understand the layout of a <code>.pbs</code> job script file</li>
<li>Get a feel for the <code>qsub</code> command</li>
</ul>
<h2 id="c-boilerplate"><a class="header" href="#c-boilerplate">C++ Boilerplate</a></h2>
<p>First, let's start by creating a folder for our projects, then a folder for C++, and finally a folder for this project:</p>
<pre><code class="language-bash">$ mkdir ~/projects
$ mkdir ~/projects/cpp
$ mkdir ~/projects/cpp/cpp_on_metis
$ cd ~/projects/cpp/cpp_on_metis
</code></pre>
<p>Let's start by creating a <code>main.cpp</code> file with the following contents:</p>
<pre><code class="language-c++">#include &lt;iostream&gt;

int main () {
    // Say hello to the user
    std::cout &lt;&lt; "Hello, Metis!" &lt;&lt; std::endl;

    // Initialize our counter variables
    unsigned long long int counter = 0;
    unsigned long long int number_of_divisible_by_two = 0;
    unsigned long long int number_of_divisible_by_three = 0;
    unsigned long long int number_of_divisible_by_five = 0;

    // First, iterate through a 3D grid to get to our block
    for ( int grid_z = 0; grid_z &lt; 1000; grid_z++ ) {
        for ( int grid_y = 0; grid_y &lt; 100; grid_y++ ) {
            for ( int grid_x = 0; grid_x &lt; 100; grid_x++ ) {

                // Second, iterate through the 3D block
                for ( int block_z = 0; block_z &lt; 10; block_z++ ) {
                    for ( int block_y = 0; block_y &lt; 10; block_y++ ) {
                        for ( int block_x = 0; block_x &lt; 10; block_x++ ) {
                            counter += 1;

                            if ( counter % 2 == 0 )
                                number_of_divisible_by_two += 1;
                            if ( counter % 3 == 0 )
                                number_of_divisible_by_three += 1;
                            if ( counter % 5 == 0 )
                                number_of_divisible_by_five += 1;
                        }
                    }
                }

            }
        }
    }

    // Provide our results to the user
    std::cout &lt;&lt; std::endl
              &lt;&lt; "- Numbers divisible by two: "       &lt;&lt; number_of_divisible_by_two       &lt;&lt; std::endl
              &lt;&lt; "- Numbers divisible by three: "     &lt;&lt; number_of_divisible_by_three     &lt;&lt; std::endl
              &lt;&lt; "- Numbers divisible by five: "      &lt;&lt; number_of_divisible_by_five      &lt;&lt; std::endl;

    return 0;
}
</code></pre>
<p>This program does two things - it says hello to the user, and then takes count of the numbers divisible by 2, 3, and 5 from 0 up to 10 billion.</p>
<p>This is done with multiple nested loops - the reason for which will be explained, and the code optimized, in the following chapter on CUDA.</p>
<p>For now, what's apparent and important is that this is a computationally intensive task!</p>
<p>Next, let's build and run this code. By default, Metis users have GCC and G++ (version 11.3.0) preinstalled, which we will now use:</p>
<pre><code class="language-bash">$ g++ -o hello_world main.cpp
$ ./hello_world
</code></pre>
<p>After ten to twenty seconds, we should see our results!</p>
<h2 id="getting-started-with-pbs"><a class="header" href="#getting-started-with-pbs">Getting Started with PBS</a></h2>
<p>We are not currently making full use of Metis with this current setup. What we just ran our code on is called the <strong>login node</strong>, which has nowhere near the amount of computational power that is available to the <strong>compute nodes</strong>, which are where computationally intensive or time-consuming programs should be run.</p>
<p>But how do we do so?</p>
<p>Metis has many users, and each user may have various types of programs, each program with varying hardware requirements. As such, Metis uses a resource manager and job scheduling system by Altair, called <a href="https://altair.com/pbs-professional">PBS Professional</a>.</p>
<p>In order to make use of this program, we must describe to the system what we need from it, which could be things such as:</p>
<ul>
<li>CPU cores</li>
<li>CPU count</li>
<li>RAM size</li>
<li>GPU chunks</li>
<li>Estimated runtime</li>
</ul>
<p>...and more.</p>
<p>To do so, we use a PBS script file. For those familiar with systems scripting, this is similar to a <code>.sh</code> file on Linux, or a <code>.bat</code> file on Windows.</p>
<p>Let's get started by creating a <code>run.pbs</code> file with the following contents:</p>
<pre><code class="language-bash">#!/bin/bash

#PBS -N hello_world
#PBS -j oe

#Note - on Metis
#              Nchunks&lt;=32, for GPU chunks
#              Nchunks&lt;=4096/Ncpus for CPU-only chunks
#              (run 'shownodes' command to find the number of free cpus)
#              Ncpus&lt;=128, the total number of CPUs per node is 128
#              NPmpi&lt;=Ncpus, the total number of CPUs allocated for MPI tasks,
#                              request NPmpi=Ncpus for non-OPENMP jobs
#              Ngpus==1,  the total number of GPUs per node is 1
#              X&lt;=256,  28 of 32 Metis modes have 256 GB of RAM
#                       special jobs can request up to 1024 GB of RAM (4 nodes)
#
# Below, we request two chunks;
#  each chunk needs 8 CPUs, 8 MPI processes, 1 GPU card, and 16 GB RAM
#PBS -l select=1:ncpus=1:mpiprocs=1:ngpus=1:mem=2gb
#PBS -l walltime=00:15:00

# When to send a status email ("-m abe" sends e-mails at job abort, begin, and end)
#--PBS -m ae
#--#PBS -M account@niu.edu

# Navigate to our working directory
PROJECT_DIRECTORY=/home/&lt;your_account_username&gt;/projects/cpp/cpp_on_metis
echo "The job's working directory is $PROJECT_DIRECTORY"
cd $PROJECT_DIRECTORY

# Install GCC
echo ""
echo "Loading GCC..."
module purge; module load gcc/gcc-12.3.0
module list
echo "Done!"

# Compile our code
echo ""
echo "Compiling code..."
g++ main.cpp -o hello_world
echo "Done!"

# Run our binary
echo ""
echo "Executing binary..."
./hello_world
echo "Done!"

# Clean up our binary
rm ./hello_world
</code></pre>
<p>Before we move on, let's dissect what this does.</p>
<pre><code class="language-bash">1.  #!/bin/bash
2.
3.  #PBS -N hello_world
4.  #PBS -j oe
5.  
6.  #Note - on Metis
7.  #              Nchunks&lt;=32, for GPU chunks
8.  #              Nchunks&lt;=4096/Ncpus for CPU-only chunks
9.  #              (run 'shownodes' command to find the number of free cpus)
10. #              Ncpus&lt;=128, the total number of CPUs per node is 128
11. #              NPmpi&lt;=Ncpus, the total number of CPUs allocated for MPI tasks,
12. #                              request NPmpi=Ncpus for non-OPENMP jobs
13. #              Ngpus==1,  the total number of GPUs per node is 1
14. #              X&lt;=256,  28 of 32 Metis modes have 256 GB of RAM
15. #                       special jobs can request up to 1024 GB of RAM (4 nodes)
16. #
17. # Below, we request two chunks;
18. #  each chunk needs 8 CPUs, 8 MPI processes, 1 GPU card, and 16 GB RAM
19. #PBS -l select=1:ncpus=1:mpiprocs=1:ngpus=1:mem=2gb
20. #PBS -l walltime=00:15:00
21. 
22. # When to send a status email ("-m abe" sends e-mails at job abort, begin, and end)
23. #--PBS -m ae
24. #--#PBS -M account@niu.edu

...
</code></pre>
<p><em>Lines starting with <code>#PBS</code> are not comments, rather, they are PBS-specific commands!</em></p>
<p>The following lines are important to understand:</p>
<ul>
<li>Line 1 is a <a href="https://en.wikipedia.org/wiki/Shebang_%28Unix%29">shebang</a> which specifies that the file's commands are to be interpreted by <a href="https://www.gnu.org/software/bash/manual/bash.html">bash</a>.</li>
<li>Line 3 specifies the name of our file.</li>
<li>Line 19 specifies the hardware requirements for our job</li>
<li>Line 20 specifies the estimated runtime of our job</li>
<li>Lines 23 and 24 specify options for recieveing emails regarding various events</li>
</ul>
<p>For this job, none of this needs to be modified. The next section, however, will need to be:</p>
<pre><code class="language-bash">...

26. # Navigate to our working directory
27. PROJECT_DIRECTORY=/home/&lt;your_account_username&gt;/projects/cpp/cpp_on_metis
28. echo "The job's working directory is $PROJECT_DIRECTORY"
29. cd $PROJECT_DIRECTORY

...
</code></pre>
<p>It's important that we hard-code the exact path on line 27 by replacing <code>&lt;your_account_username&gt;</code> with your Metis account's username.</p>
<p>The reason for this only becomes relevant if you have interest in creating non-C++ projects or automating your job submission, so it is worth noting that you can replace <code>/home/&lt;your_account_username&gt;/projects/cpp/cpp_on_metis</code> with <code>$PBS_O_WORKDIR</code> if you would like. This will be populated with where the job is run from.</p>
<p>Next, we will familiarize ourselves with the <code>module</code> commands, which are used on lines 31-36:</p>
<pre><code class="language-bash">...

31. # Install GCC
32. echo ""
33. echo "Loading GCC..."
34. module purge; module load gcc/gcc-12.3.0
35. module list
36. echo "Done!"

...
</code></pre>
<p>The <code>module</code> commands are somewhat akin to a package manager, allowing you to load packages ("modulefiles") into your environment.</p>
<p>Unlike you, the compute node does not have <code>gcc</code> pre-installed. So to make it available to the compute node, we must install it, done in the following fashion:</p>
<ul>
<li>Line 34 clears all packages with <code>module purge</code>, then installs GCC with <code>module load gcc/gcc-12.3.0</code>.</li>
<li>Line 35 lets you see what's currently installed with <code>module list</code>.</li>
</ul>
<p>This process for installing a package is the same on both the login and compute nodes. To see what packages are available to you, you can run <code>module av</code>. To narrow your search by a specific key word, use <code>module av &lt;keyword&gt;</code>.</p>
<pre><code class="language-bash">...

38. # Compile our code
39. echo ""
40. echo "Compiling code..."
41. g++ main.cpp -o hello_world
42. echo "Done!"
43. 
44. # Run our binary
45. echo ""
46. echo "Executing binary..."
47. ./hello_world
48. echo "Done!"
49. 
50. # Clean up our binary
51. rm ./hello_world

...
</code></pre>
<p>The remaining lines are what you are accustomed to, they use the same build command from before, then run the binary, and finally clean up any artifacts.</p>
<h2 id="launching-a-job-with-pbs"><a class="header" href="#launching-a-job-with-pbs">Launching a Job with PBS</a></h2>
<p>We're ready to go! All that's left is to start our job, which can be done easily with the following command:</p>
<pre><code class="language-bash">$ qsub run.pbs
</code></pre>
<p>The output will look something like this:</p>
<pre><code class="language-bash">18681.cm
</code></pre>
<p>This tells us the ID number of our job. Wait around 30 seconds for the job to finish, and list the contents of the directory!</p>
<pre><code class="language-bash">$ ls
hello_world.o18681 main.cpp run.pbs
</code></pre>
<p>Reading the output from our job:</p>
<pre><code>$ cat hello_world.o18681
The job's working directory is /home/&lt;your_account_username&gt;/projects/cpp/cpp_on_metis

Loading GCC...
Currently Loaded Modulefiles:
 1) gcc/gcc-12.3.0  
Done!

Compiling code...
Done!

Executing binary...
Hello, Metis!

- Numbers divisible by two: 5000000000
- Numbers divisible by three: 3333333333
- Numbers divisible by five: 2000000000
Done!
</code></pre>
<h2 id="closing-thoughts"><a class="header" href="#closing-thoughts">Closing Thoughts</a></h2>
<p>Congratulations! You've successfully launched your first job on the Metis supercomputer.</p>
<p>This is an impressive achievement. Those who are satisfied with the performance of their programs and are comfortable with only using the C family may even be able to stop here.</p>
<p>However, Metis is capable of much, much more.</p>
<p>In the next chapter, we will discuss utilizing CUDA to weaponize the power of graphics card programming to drastically reduce the computation times of our programs, as well as learning more about the <code>module</code> and PBS-related commands.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="22-building-a-cuda-project-from-the-ground-up"><a class="header" href="#22-building-a-cuda-project-from-the-ground-up">2.2. Building a CUDA Project from the Ground Up</a></h1>
<p><em>You can find the code mentioned in this chapter <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/cuda/cuda_on_metis">in this book's repository</a>!</em></p>
<p>The next part of this introductory chapter will teach you how to build, compile, and run a CUDA program from the ground up on Metis.</p>
<p>CUDA stands for Compute Unified Device Architecture, and it is proprietary NVIDIA-distributed software that allows developers to perform matrice-based operations at unbelievable speeds using the heavily optimized CUDA cores found only on NVIDIA GPUs.</p>
<p>This chapter will teach you how to run CUDA code on Metis, but it will not teach you how to write it!</p>
<p>There are many fantastic resources on how to write it, some of which are linked below:</p>
<ul>
<li><a href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">(NVIDIA) An Even Easier Introduction to CUDA</a></li>
<li><a href="https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/">(cuda-tutorial) Introduction to CUDA</a></li>
<li><a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html">(NVIDIA) CUDA Runtime API Reference</a></li>
<li><a href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html">(NVIDIA) CUDA Driver API Reference</a></li>
</ul>
<h2 id="goals-1"><a class="header" href="#goals-1">Goals</a></h2>
<ul>
<li>Learn how to use the <code>module</code> commands on the login node</li>
<li>Learn how to use the <code>qstat</code> command to view a running or completed job</li>
</ul>
<h2 id="cuda-boilerplate"><a class="header" href="#cuda-boilerplate">CUDA Boilerplate</a></h2>
<p>If you did not in the previous section, start by creating a folder for our projects, then a folder for CUDA projects, and finally a folder for this project:</p>
<pre><code class="language-bash">$ mkdir ~/projects
$ mkdir ~/projects/cuda
$ mkdir ~/projects/cuda/cuda_on_metis
$ cd ~/projects/cuda/cuda_on_metis
</code></pre>
<p>Let's start by creating a <code>main.cu</code> file with the following contents:</p>
<pre><code class="language-c++">#include &lt;iostream&gt;

/// A kernel function designed to calculate the number of
///  numbers divisible by two, three, and five
///
/// # Arguments
/// * `d_number_of_divisible_by_two` - The number of numbers divisible by two
/// * `d_number_of_divisible_by_three` - The number of numbers divisible by three
/// * `d_number_of_divisible_by_five` - The number of numbers divisible by five
__global__ void calculate(
    unsigned long long int * d_number_of_divisible_by_two,
    unsigned long long int * d_number_of_divisible_by_three,
    unsigned long long int * d_number_of_divisible_by_five
) {
    int grid_x = blockIdx.x;
    int grid_y = blockIdx.y;
    int grid_z = blockIdx.z;

    int block_x = threadIdx.x;
    int block_y = threadIdx.y;
    int block_z = threadIdx.z;

    unsigned long long local_counter = 
        (grid_z * 100 * 100 * 10 * 10 * 10) + 
        (grid_y * 100 * 10 * 10) + 
        (grid_x * 10 * 10) +
        (block_z * 10 * 10) +
        (block_y * 10) +
        block_x + 1;

    unsigned long one = 1;

    if (local_counter % 2 == 0) {
        atomicAdd(d_number_of_divisible_by_two, one);
    }
    if (local_counter % 3 == 0) {
        atomicAdd(d_number_of_divisible_by_three, one);
    }
    if (local_counter % 5 == 0) {
        atomicAdd(d_number_of_divisible_by_five, one);
    }
}

int main() {
    // Say hello to the user
    std::cout &lt;&lt; "Hello, Metis!" &lt;&lt; std::endl;

    // Host variables
    unsigned long long int h_number_of_divisible_by_two   = 0;
    unsigned long long int h_number_of_divisible_by_three = 0;
    unsigned long long int h_number_of_divisible_by_five  = 0;

    // Device variables
    unsigned long long int * d_number_of_divisible_by_two;
    unsigned long long int * d_number_of_divisible_by_three;
    unsigned long long int * d_number_of_divisible_by_five;

    // Allocate memory on the device with the correct sizing
    cudaMalloc( &amp;d_number_of_divisible_by_two,   sizeof(unsigned long long int) );
    cudaMalloc( &amp;d_number_of_divisible_by_three, sizeof(unsigned long long int) );
    cudaMalloc( &amp;d_number_of_divisible_by_five,  sizeof(unsigned long long int) );

    // Copy the memory from the host to the device
    cudaMemcpy( d_number_of_divisible_by_two,   &amp;h_number_of_divisible_by_two,   
        sizeof(unsigned long long int), cudaMemcpyHostToDevice );
    cudaMemcpy( d_number_of_divisible_by_three, &amp;h_number_of_divisible_by_three,
        sizeof(unsigned long long int), cudaMemcpyHostToDevice );
    cudaMemcpy( d_number_of_divisible_by_five,  &amp;h_number_of_divisible_by_five,
        sizeof(unsigned long long int), cudaMemcpyHostToDevice );

    // Define our grid's dimensions
    dim3 gridDim(100, 100, 10);

    // Define each block's dimensions
    dim3 blockDim(10, 10, 10);

    // Run our calculation
    calculate&lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;(d_number_of_divisible_by_two, d_number_of_divisible_by_three, d_number_of_divisible_by_five);
    cudaDeviceSynchronize();

    // Copy the memory back to our machine
    cudaMemcpy(&amp;h_number_of_divisible_by_two, d_number_of_divisible_by_two, sizeof(unsigned long long int), cudaMemcpyDeviceToHost);
    cudaMemcpy(&amp;h_number_of_divisible_by_three, d_number_of_divisible_by_three, sizeof(unsigned long long int), cudaMemcpyDeviceToHost);
    cudaMemcpy(&amp;h_number_of_divisible_by_five, d_number_of_divisible_by_five, sizeof(unsigned long long int), cudaMemcpyDeviceToHost);

    // Provide our results to the user
    std::cout &lt;&lt; std::endl
              &lt;&lt; "- Numbers divisible by two: "       &lt;&lt; h_number_of_divisible_by_two       &lt;&lt; std::endl
              &lt;&lt; "- Numbers divisible by three: "     &lt;&lt; h_number_of_divisible_by_three     &lt;&lt; std::endl
              &lt;&lt; "- Numbers divisible by five: "      &lt;&lt; h_number_of_divisible_by_five      &lt;&lt; std::endl;

    // Free the memory
    cudaFree(d_number_of_divisible_by_two);
    cudaFree(d_number_of_divisible_by_three);
    cudaFree(d_number_of_divisible_by_five);

    return 0;
}
</code></pre>
<p>This program does the exact same thing as the previous section, with one key difference - it makes use of the CUDA runtime.</p>
<p>Instead of using indicied loops, we run our program using the compute systems of CUDA.</p>
<ul>
<li>Our outer loop's dimensions are replaced by the CUDA (thread) block grid, 1-3D grid containing (thread) block.</li>
<li>Our inner loop's dimensions are replaced by the CUDA thread block, which are a 1-3D block containing the threads our kernel function will be executed on.</li>
</ul>
<p>In our program, we use the maximum number of dimensions, effectively creating a 6D matrix. Because each each block is aware of its coordinates on the grid it lies on, and each thread the coordinates of the block it sits in, we can use sneaky math to calculate which number the old "counter" variable each of the <em>ten billion</em> threads translates to.</p>
<p>If you would like to learn more about CUDA, the resources in the introductory section of this paragraph are greatly recommended.</p>
<h2 id="installing-modules-on-the-login-node"><a class="header" href="#installing-modules-on-the-login-node">Installing Modules on the Login Node</a></h2>
<p>However, unlike our previous project which used <code>g++</code>, the CUDA compiler, <code>nvcc</code>, is not pre-installed.</p>
<p>To install it, we will use the <code>module</code> commands mentioned briefly in the previous section.</p>
<p>First, let's list the modules related to <code>cuda</code> with the following command:</p>
<pre><code class="language-bash">$ module av cuda
-------------------------------------------------- /etc/modulefiles --------------------------------------------------
cuda/cuda-7.5  cuda/cuda-8.0  cuda/cuda-11.5  cuda/cuda-11.8  cuda/cuda-11.8-rocky8  cuda/cuda-12.2
</code></pre>
<p>We see a variety of versions. For the sake of this guide, we will be using <code>cuda/cuda-11.8</code>.</p>
<p>Next, let's clean up our modules, and install CUDA:</p>
<pre><code class="language-bash">$ module purge
$ module load cuda/cuda-11.8
$ module list
Currently Loaded Modulefiles:
 1) cuda/cuda-11.8
</code></pre>
<p>Finally, we're ready to go! Let's compile and run our program:</p>
<pre><code class="language-bash">$ nvcc -o hello_world main.cu
$ ./hello_world
Hello, Metis!

- Numbers divisible by two: 50000000
- Numbers divisible by three: 33333333
- Numbers divisible by five: 20000000
</code></pre>
<p>You will notice a nearly instantaneous completion time, versus the 20-30 seconds of the previous C version.</p>
<p>Such is the power of graphical programming!</p>
<h2 id="launching-a-cuda-program-with-pbs"><a class="header" href="#launching-a-cuda-program-with-pbs">Launching a CUDA Program with PBS</a></h2>
<p>For the most part, the <code>run.pbs</code> file will look similar to the version from the previous chapter.</p>
<p>Create a <code>run.pbs</code> file with the following contents:</p>
<pre><code class="language-bash">#!/bin/bash

#PBS -N hello_world_cuda
#PBS -j oe

#Note - on Metis
#              Nchunks&lt;=32, for GPU chunks
#              Nchunks&lt;=4096/Ncpus for CPU-only chunks
#              (run 'shownodes' command to find the number of free cpus)
#              Ncpus&lt;=128, the total number of CPUs per node is 128
#              NPmpi&lt;=Ncpus, the total number of CPUs allocated for MPI tasks,
#                              request NPmpi=Ncpus for non-OPENMP jobs
#              Ngpus==1,  the total number of GPUs per node is 1
#              X&lt;=256,  28 of 32 Metis modes have 256 GB of RAM
#                       special jobs can request up to 1024 GB of RAM (4 nodes)
#
# Below, we request two chunks;
#  each chunk needs 8 CPUs, 8 MPI processes, 1 GPU card, and 16 GB RAM
#PBS -l select=1:ncpus=1:mpiprocs=1:ngpus=1:mem=2gb
#PBS -l walltime=00:15:00

# When to send a status email ("-m abe" sends e-mails at job abort, begin, and end)
#--PBS -m ae
#--#PBS -M account@niu.edu

# Navigate to our working directory
PROJECT_DIRECTORY=/home/&lt;your_account_username&gt;/projects/cuda/cuda_on_metis
echo "The job's working directory is $PROJECT_DIRECTORY"
cd $PROJECT_DIRECTORY

# Install GCC
echo ""
echo "Loading CUDA"
module purge; module load cuda/cuda-11.8; module load gcc/gcc-11.3.0
module list
echo "Done!"

# Compile our code
echo ""
echo "Compiling code..."
nvcc -o hello_world main.cu
echo "Done!"

# Run our binary
echo ""
echo "Executing binary..."
./hello_world
echo "Done!"

# Clean up our binary
rm ./hello_world
</code></pre>
<p>There are a few notable differences.</p>
<ul>
<li>Our project name is <code>hello_world_cuda</code> instead of <code>hello_world</code>.</li>
<li>Our project directory is <code>.../hello_world_cuda</code> instead of <code>.../hello_world</code>.</li>
<li>Instead of loading GCC, we loaded CUDA (<code>module load cuda/cuda-11.8</code>).</li>
<li>Instead of compiling with G++ (<code>g++ -o hello_world main.cpp</code>), we compiled with CUDA (<code>nvcc -o hello_world main.cu</code>).</li>
</ul>
<p>Be sure to replace any instances of <code>&lt;your_account_username&gt;</code> with your Metis username!</p>
<h2 id="launching-our-job-with-pbs"><a class="header" href="#launching-our-job-with-pbs">Launching our Job with PBS</a></h2>
<p>We're ready to go! All that's left is to start our job, which can be done easily with the following command:</p>
<pre><code class="language-bash">$ qsub run.pbs
</code></pre>
<p>The output will look something like this:</p>
<pre><code class="language-bash">18681.cm
</code></pre>
<p>This tells us the ID number of our job. Wait around 30 seconds for the job to finish, and list the contents of the directory!</p>
<pre><code class="language-bash">$ ls
hello_world_cuda.o18681 main.cu run.pbs
</code></pre>
<p>Reading the output from our job:</p>
<pre><code>$ cat hello_world.o18681
The job's working directory is /home/&lt;your_account_username&gt;/projects/cuda/cuda_on_metis

Loading GCC...
Currently Loaded Modulefiles:
 1) gcc/gcc-12.3.0  
Done!

Compiling code...
Done!

Executing binary...
Hello, Metis!

- Numbers divisible by two: 5000000000
- Numbers divisible by three: 3333333333
- Numbers divisible by five: 2000000000
Done!
</code></pre>
<p>It's also worth noting that you can use the <code>qstat</code> command to view the status of a job:</p>
<pre><code>$ qstat -x 18681
Job id            Name             User              Time Use S Queue
----------------  ---------------- ----------------  -------- - -----
18681.cm          hello_world      z1994244          00:00:02 F short 
</code></pre>
<p>The <code>-x</code> flag means you will recieve output even if the job has concluded.</p>
<p>The documentation for this command, as well as <code>qsub</code>, can be found below:</p>
<ul>
<li><a href="https://www.jlab.org/hpc/PBS/qsub.html">(jlab) Documetation: <code>qsub</code></a></li>
<li><a href="https://www.jlab.org/hpc/PBS/qstat.html">(jlab) Documetation: <code>qstat</code></a></li>
</ul>
<p>There are also other useful commands such as <code>qdel</code> (terminates a job):</p>
<ul>
<li><a href="https://www.jlab.org/hpc/PBS/qdel.html">(jlab) Documentation: <code>qdel</code></a></li>
</ul>
<h2 id="closing-thoughts-1"><a class="header" href="#closing-thoughts-1">Closing Thoughts</a></h2>
<p>Once again, congratulations! You have just harnessed the power of the NVIDIA hardware on Metis.</p>
<p>The boilerplate from this project will be enough to get almost any CUDA project up and running. For those who recieve enough of a performance improvement to satisfy your needs, you may be able to stop here.</p>
<p>For tasks that require even further optimization, Metis supports <a href="https://www.open-mpi.org/">OpenMPI</a>, a message passing interface which allows for massively parallel computation across multiple CPUs/Metis nodes.</p>
<p>Metis has modules containing GCC, CUDA, and OpenMPI for your convenience:</p>
<pre><code class="language-bash">$ module av openmpi
-------------------- /etc/modulefiles ---------------------
openmpi/openmpi-1.8.8-gcc-11.4.0            
openmpi/openmpi-4.0.7-gcc-9.5.0-cuda-11.8   
openmpi/openmpi-4.1.1-gcc-11.3.0-cuda-11.8  
openmpi/openmpi-4.1.5-gcc-8.5.0-cuda-11.8   
openmpi/openmpi-4.1.5-gcc-11.4.0-cuda-11.8  
openmpi/openmpi-4.1.5-gcc-12.3.0-cuda-12.2  
openmpi/openmpi-4.1.6-gcc-11.4.0-cuda-11.8
</code></pre>
<p>Using a combination of both OpenMPI for coordinating large-scale tasks across many processors and CUDA for handling tasks best accelerated by GPU programming will allow you to fully harness the hardware of Metis.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="3-intermediate-metis-usage-with-metis"><a class="header" href="#3-intermediate-metis-usage-with-metis">3. Intermediate Metis Usage with Metis</a></h1>
<p>In this chapter, we will dive deeper into advanced Docker techniques, expanding on the foundational knowledge covered in Chapters 2.1 and 2.2.</p>
<p>We'll explore how to combine these techniques to create a robust workflow for your projects on Metis, including handling custom Docker images, leveraging GPU acceleration, and managing complex dependencies.</p>
<h2 id="overview-of-the-chapters-1"><a class="header" href="#overview-of-the-chapters-1">Overview of the Chapters</a></h2>
<h3 id="chapter-31-using-pre-made-docker-images"><a class="header" href="#chapter-31-using-pre-made-docker-images">Chapter 3.1: Using Pre-Made Docker Images</a></h3>
<ul>
<li><strong>Goals</strong>: Understand the limitations of Metis modulefiles and learn how to circumvent them using Docker.</li>
<li><strong>Problem</strong>: Some software, like Python 3.11, isn't available on Metis, and creating modulefiles can be time-consuming.</li>
<li><strong>Solution</strong>: Use Docker (via Podman) to run applications with custom dependencies.</li>
<li><strong>Outcome</strong>: You will be able to run any version of software, regardless of the limitations of the Metis environment.</li>
</ul>
<h3 id="chapter-32-using-gpu-acceleration-with-docker"><a class="header" href="#chapter-32-using-gpu-acceleration-with-docker">Chapter 3.2: Using GPU Acceleration with Docker</a></h3>
<ul>
<li><strong>Goals</strong>: Learn how to enable GPU passthrough in Docker containers on Metis.</li>
<li><strong>Problem</strong>: GPUs are not accessible in Docker by default, and additional steps are required to set up NVIDIA drivers and CUDA.</li>
<li><strong>Solution</strong>: Configure Podman with specific flags and use NVIDIA's CUDA-enabled Docker images.</li>
<li><strong>Outcome</strong>: You will be able to leverage GPU acceleration for your Dockerized applications, significantly boosting performance.</li>
</ul>
<h3 id="chapter-33-creating-your-own-docker-base-images"><a class="header" href="#chapter-33-creating-your-own-docker-base-images">Chapter 3.3: Creating Your Own Docker Base Images</a></h3>
<ul>
<li><strong>Goals</strong>: Gain the skills to create custom Docker images tailored to your project’s needs.</li>
<li><strong>Problem</strong>: Pre-made Docker images may not always meet the specific requirements of your project.</li>
<li><strong>Solution</strong>: Learn the basics of writing Dockerfiles, building custom images, and publishing them to public repositories.</li>
<li><strong>Outcome</strong>: You will be able to create, customize, and share Docker images, enabling a flexible and reproducible environment for your work.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="31-using-pre-made-docker-images"><a class="header" href="#31-using-pre-made-docker-images">3.1. Using Pre-Made Docker Images</a></h1>
<p><em>You can find the code mentioned in this chapter <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/docker/premade_image">in this book's repository</a>!</em></p>
<p>We will first begin by using a language which is <em>not</em> among the modules which Metis provides, Python 3.11.</p>
<p>In actuality, Metis does offer Python, as seen below:</p>
<pre><code>$ module av python
-------------------- /etc/modulefiles ---------------------
python/python-3.9.10  python/python-3.12.4
</code></pre>
<p>...but, at the time of writing this, it does not have Python 3.11, which is among the most commonly used versions.</p>
<p>So, how do we fix this?</p>
<p>Well, we ourselves can't fix the global modulefiles on Metis, which means under normal circumstances, we would have to reach out to Metis staff to have the module fixed - something that takes away from both your own time and the time of the Metis staff.</p>
<p>You are able to define your own modulefiles, but this is a time consuming task, and it can't solve everything.</p>
<h2 id="goals-2"><a class="header" href="#goals-2">Goals</a></h2>
<ul>
<li>Learn how to use Podman and Docker</li>
<li>Learn how to install dependencies via Podman's CLI</li>
<li>Learn how to use Podman in a PBS script file</li>
<li>Learn how to kill Podman to avoid uptime emails and alerts</li>
</ul>
<h2 id="the-problem"><a class="header" href="#the-problem">The Problem</a></h2>
<p>Modulefiles struggle or are outright impossible to create with any of the following cases:</p>
<ul>
<li>Packages which can only run on certain operating systems, and specific versions of those operating systems</li>
<li>Packages which have dense dependency trees</li>
<li>Packages which have circular dependencies</li>
<li>Packages which need elevated permissions</li>
<li>Packages with long build times, where a distributed binary may be preferred</li>
<li>Closed-source or unfree packages (which are very common in machine learning!)</li>
<li>Huge numbers of dependencies</li>
</ul>
<p>This isn't to say it's impossible to manually build every single dependency for your project, and also include them manually.</p>
<p>However, this is an <strong>extremely</strong> time-consuming process, and time spent doing this will only take away from your core work.</p>
<p>Dependency installation should be a matter of lines, not weeks.</p>
<h2 id="the-solution"><a class="header" href="#the-solution">The Solution</a></h2>
<p><a href="https://www.docker.com/">Docker</a>, an extremely powerful containerization and encapsulation tool that allows developers to define virtual machines with a level of granularity rarely found in modern computing. Docker allows you to select an operation system as a base, install packages and libraries, and define run behaviour.</p>
<p>We will be using an overlay on Docker called <a href="https://podman.io/">Podman</a>. It allows us to use Docker containers despite not having elevated permissions on Metis. Understanding of Podman isn't required - all Docker commands can have <code>docker</code> replaced with <code>podman</code> (or in our case, <code>/bin/podman</code>).</p>
<p>If you haven't already, create your projects directory, a new directory for Docker projects, and finally a directory for this project:</p>
<pre><code class="language-bash">$ mkdir ~/projects
$ mkdir ~/projects/docker
$ mkdir ~/projects/docker/premade_image
$ cd ~/projects/docker/premade_image
</code></pre>
<p>Next, let's create a <code>main.py</code> file with the following contents:</p>
<pre><code class="language-python">print( "Hello, Metis!" )
</code></pre>
<p>Now, how do we get Docker to run this file?</p>
<p>For your own projects, you can search the <a href="https://hub.docker.com/">Docker Hub</a> for programming languages, software, and more. You can also use a base image like <code>ubuntu:22.04</code> or <code>debian:bookworm</code>, which contain nothing but the operating system with no additional packages or programming languages.</p>
<p>From there, you can use the <code>exec</code> command to install the languages or packages with that operating system's respective package manager. We will go over the usage of the <code>exec</code> command with examples shortly!</p>
<p>We'll start by downloading and running a <a href="https://docs.docker.com/guides/docker-concepts/the-basics/what-is-an-image/">Docker Image</a>, which will be built on the Debian operating system version 12.6 "Bookworm", and include Python 3.11.9:</p>
<pre><code>$ /bin/podman run             \
    -v ./.:/home            \
    -w /home                \
    --name python_container \
    -t -d                   \
    python:3.12.5-bookworm
WARN[0000] Network file system detected as backing store.  Enforcing overlay option `force_mask="700"`.  Add it to storage.conf to silence this warning 
f258979e09d0923ebb815b0b0baae9ae9cb2de18ace02a4aa282920c673073d9
</code></pre>
<p>The first line with the warning can be safely ignored. It's likely that by the time you are reading this, it's been silenced.</p>
<p>Next, let's run our Python script!</p>
<pre><code>$ /bin/podman exec python_container python3 main.py
...
Hello, World!
</code></pre>
<p>Congratulations! You've just run a version of Python that's not installed on Metis at all. But, what if our Python script needed some dependencies?</p>
<p>Overwrite the <code>main.py</code> file with the following contents:</p>
<pre><code class="language-python">import numpy as np

print( "Hello, Metis!" )
</code></pre>
<p>If we try to run our script again, we get an error:</p>
<pre><code>$ /bin/podman exec python_container python3 main.py
...
Traceback (most recent call last):
  File "/home/main.py", line 1, in &lt;module&gt;
    import numpy as np
ModuleNotFoundError: No module named 'numpy'
</code></pre>
<p>Let's create our <a href="https://docs.python.org/3/library/venv.html">Python virtual environment</a>, and install <code>numpy</code> using the <code>exec</code> command! Run the following:</p>
<pre><code class="language-bash">$ /bin/podman exec python_container python -m venv .venv
$ /bin/podman exec python_container .venv/bin/pip install numpy
</code></pre>
<p>Running our script again:</p>
<pre><code>$ /bin/podman exec python_container .venv/bin/python3 main.py
...
Hello, Metis!
</code></pre>
<p>Nicely done! Lastly, let's kill and remove our container:</p>
<pre><code class="language-bash">$ /bin/podman kill python_container
$ /bin/podman rm python_container
</code></pre>
<p>Again, congratulations! You've successfully downloaded a Docker Image, installed some dependancies, and run them on the login node!</p>
<h2 id="docker-in-pbs"><a class="header" href="#docker-in-pbs">Docker in PBS</a></h2>
<p>Now, we just ran that Docker image on the <em>login node</em>, not the compute nodes. So how do we write a PBS file to automate what we just did?</p>
<p>Create a <code>run.pbs</code> file with the following contents:</p>
<pre><code class="language-bash">#!/bin/bash

#PBS -N premade_image
#PBS -j oe

#Note - on Metis   
#              Nchunks&lt;=32, for GPU chunks
#              Nchunks&lt;=4096/Ncpus for CPU-only chunks
#              (run 'shownodes' command to find the number of free cpus) 
#              Ncpus&lt;=128, the total number of CPUs per node is 128 
#              NPmpi&lt;=Ncpus, the total number of CPUs allocated for MPI tasks, 
#                              request NPmpi=Ncpus for non-OPENMP jobs                           
#              Ngpus==1,  the total number of GPUs per node is 1    
#              X&lt;=256,  28 of 32 Metis modes have 256 GB of RAM                       
#                       special jobs can request up to 1024 GB of RAM (4 nodes)
#
# Below, we request two chunks;
#  each chunk needs 8 CPUs, 8 MPI processes, 1 GPU card, and 16 GB RAM
#PBS -l select=1:ncpus=1:mpiprocs=1:ngpus=1:mem=2gb
#PBS -l walltime=00:15:00

# When to send a status email ("-m abe" sends e-mails at job abort, begin, and end)
#--PBS -m ae
#--#PBS -M account@niu.edu

PROJECT_DIRECTORY=/home/&lt;your_account_name&gt;/projects/docker/premade_image
echo "This job's working directory is $PROJECT_DIRECTORY"
cd $PROJECT_DIRECTORY

# Enable linger for the user
echo ""
echo "Enabling linger for the user..."
loginctl enable-linger &lt;your_account_name&gt;
echo "Done!"

# Start the container
# 
# There are five flags, most of which will never change:
# - `-v $PROJECT_DIRECTORY:/home` mounts the project directory to the `/home` 
#    directory in the container.
# - `-w /home` sets the working directory in the container to `/home`.
# - `-t` allocates a pseudo-TTY. This is useful for running the container in
#    the background.
# - `-d` runs the container in the background.
#
# The last argument is the image name. This is the only thing that will change
#  between projects, this is the name of the image we want to run.
# 
# For instance, in this case, we are running the `python:3.12.5-bookworm` image:
# - `python` is the name of the image.
# - `3.12.5-bookworm` is the tag of the image, which specifies the version of the
#    image we want to run.
#
# Millions of pre-built images are available on Docker Hub, and will likely 
#  already have an image that suits your needs! You can search for images here:
#  https://hub.docker.com/
#
# Note: There may be many logs that are printed to the console when the container
#  is started. Despite being error-level, this is normal, and you can ignore them.
echo ""
echo "Starting the container..."
/bin/podman run                  \
    -v $PROJECT_DIRECTORY:/home  \
    -w /home                     \
    --name python_container      \
    -t -d                        \
    python:3.12.5-bookworm       \
    &gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"

# Run our python script
#
# The `exec` command runs a command in a running container. In this case, we are
#  running the `python3 main.py` command in the `python_container` container.
# 
# There is a generic error message, which can be ignored.
echo ""
echo "Running the python script..."
/bin/podman exec python_container .venv/bin/python3 main.py
echo "Done!"

# Kill the container
#
# The `kill` command stops a running container. In this case, we are stopping the
#  `python_container` container.
echo ""
echo "Stopping the container..."
/bin/podman kill python_container \
    &gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"

# Remove the container
#
# The `rm` command removes a container. In this case, we are removing the
#  `python_container` container.
echo ""
echo "Removing the container..."
/bin/podman rm python_container \
    &gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"
</code></pre>
<p>This is largly the same, and only two things need to be modified to fit your Metis account:</p>
<pre><code>...

PROJECT_DIRECTORY=/home/&lt;your_account_name&gt;/projects/docker/premade_image
echo "This job's working directory is $PROJECT_DIRECTORY"
cd $PROJECT_DIRECTORY

# Enable linger for the user
echo ""
echo "Enabling linger for the user..."
loginctl enable-linger &lt;your_account_name&gt;
echo "Done!"

...
</code></pre>
<p>Be sure to replace the two <code>&lt;your_account_name&gt;</code> instances with your own account! The linger command is unique to Podman (Docker) jobs in PBS, and ensures it has the nessecary permissions to run your jobs.</p>
<p>With that, let's test our job!</p>
<pre><code>$ qsub run.pbs
18712.cm
$ cat premade_image.o18712
This job's working directory is /home/&lt;your_account_name&gt;/projects/docker/premade_image

Enabling linger for the user...
Done!

Starting the container...
Done!

Running the python script...
time="2024-08-16T14:57:08-05:00" level=warning msg="Network file system detected as backing store.  Enforcing overlay option `force_mask=\"700\"`.  Add it to storage.conf to silence this warning"
Error: can only create exec sessions on running containers: container state improper
Done!

Stopping the container...
Done!

Removing the container...
Done!
</code></pre>
<p>Lastly, we must kill off our Podman processes on the login node, or else we'll recieve emails about extended uptime.</p>
<p>There are many, so it's easier to kill instead everything under your username. This will close your shell connection, so please save any unfinished work before doing so.</p>
<p>This will cause additional load times next time you login to Metis (10-20 seconds), but is important to do.</p>
<pre><code class="language-bash">pkill -U &lt;your_account_username&gt;
</code></pre>
<h2 id="closing-thoughts-2"><a class="header" href="#closing-thoughts-2">Closing Thoughts</a></h2>
<p>Congratulations! You now have the skills needed to tackle most CPU-only applications.</p>
<p>You can modify the base image to fit the operating system, languages, and software you need! You can also add or modify <code>exec</code> commands to install more languages, libraries, or software to be able to load anything else your software might need.</p>
<p>If you'd like to learn more about the <code>run</code>, <code>exec</code>, <code>kill</code>, or <code>rm</code> commands, additional documentation can be found in the <strong>Conclusion and Helpful Resources</strong> chapter!</p>
<p>If your application does not make use of the GPU, and you have no interest in automation or integration, you likely don't need to read any further. If you do, then feel free to continue onto <strong>Chapter 3.2 - Using GPU Acceleration with Docker</strong>!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="32-using-gpu-acceleration-with-docker"><a class="header" href="#32-using-gpu-acceleration-with-docker">3.2. Using GPU Acceleration With Docker</a></h1>
<p><em>You can find the code mentioned in this chapter <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/docker/premade_image_gpu">in this book's repository</a>!</em></p>
<p>Now we must address how to use GPU passthrough on Metis with Podman (Docker), which can quickly elevate our programs to higher performance with the power of GPU acceleration!</p>
<h2 id="goals-3"><a class="header" href="#goals-3">Goals</a></h2>
<ul>
<li>Pass through a GPU to Podman</li>
</ul>
<h2 id="the-problems"><a class="header" href="#the-problems">The Problem(s)</a></h2>
<p>In order to do so, we must solve the following problems:</p>
<ul>
<li><strong>1</strong> - Our GPUs are not passed through to Podman (Docker) by default</li>
<li><strong>2</strong> - NVIDIA drivers and the CUDA runtime are not installed on most Docker Images</li>
<li><strong>3</strong> - NVIDIA device files aren't always loaded on the compute node</li>
</ul>
<h2 id="the-solutions"><a class="header" href="#the-solutions">The Solution(s)</a></h2>
<h3 id="1---our-gpus-are-not-passed-through-to-podman-docker-by-default"><a class="header" href="#1---our-gpus-are-not-passed-through-to-podman-docker-by-default">1 - Our GPUs are not passed through to Podman (Docker) by default</a></h3>
<p>To solve this, we add two flags to our <code>/bin/podman</code> command:</p>
<pre><code class="language-bash">$ /bin/podman run ...               \
    --device nvidia.com/gpu=all   \
    --security-opt=label=disable  \
    some/image
</code></pre>
<p>This will ensure that the GPU is passed through to our Docker Container.</p>
<h3 id="2---nvidia-drivers-and-the-cuda-runtime-are-not-installed-on-most-docker-images"><a class="header" href="#2---nvidia-drivers-and-the-cuda-runtime-are-not-installed-on-most-docker-images">2 - NVIDIA drivers and the CUDA runtime are not installed on most Docker Images</a></h3>
<p>CUDA drivers are notoriously difficult to install, so it's highly recommended to use a base image that already has them pre-installed.</p>
<p>For the purpose of this example, we will be using NVIDIA's <a href="https://hub.docker.com/r/nvidia/cuda/">base image</a>, which has CUDA pre-installed.</p>
<h3 id="3---nvidia-device-files-arent-always-loaded-on-the-compute-node"><a class="header" href="#3---nvidia-device-files-arent-always-loaded-on-the-compute-node">3 - NVIDIA device files aren't always loaded on the compute node</a></h3>
<p>Occasionally, the <code>/dev</code> files for the NVIDIA GPUs disappear on compute nodes.</p>
<p>To solve this, we use a relatively hacky but functional solution - running a CUDA-based binary to force them to load.</p>
<p>For the sake of demonstration, we'll use the binary we developed in <strong>Chapter 2.2</strong>!</p>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>First, let's create our project directory as we have in previous projects:</p>
<pre><code class="language-bash">$ mkdir ~/projects
$ mkdir ~/projects/docker
$ mkdir ~/projects/docker/premade_image_gpu
$ cd ~/projects/docker/premade_image_gpu
</code></pre>
<p>Next, we need a binary that forces CUDA to load. We'll build the project from Chapter 2.1 and have it output here:</p>
<pre><code class="language-bash">$ module purge
$ module load cuda/cuda-11.8
$ nvcc -o initialize_cuda ~/projects/cuda/cuda_on_metis/main.cu
</code></pre>
<p>Finally, we'll implement everything mentioned above.</p>
<p>Create a <code>run.pbs</code> file with the following contents:</p>
<pre><code class="language-sh">#!/bin/bash

#PBS -N premade_image_gpu
#PBS -j oe

#Note - on Metis   
#              Nchunks&lt;=32, for GPU chunks
#              Nchunks&lt;=4096/Ncpus for CPU-only chunks
#              (run 'shownodes' command to find the number of free cpus) 
#              Ncpus&lt;=128, the total number of CPUs per node is 128 
#              NPmpi&lt;=Ncpus, the total number of CPUs allocated for MPI tasks, 
#                              request NPmpi=Ncpus for non-OPENMP jobs                           
#              Ngpus==1,  the total number of GPUs per node is 1    
#              X&lt;=256,  28 of 32 Metis modes have 256 GB of RAM                       
#                       special jobs can request up to 1024 GB of RAM (4 nodes)
#
# Below, we request two chunks;
#  each chunk needs 8 CPUs, 8 MPI processes, 1 GPU card, and 16 GB RAM
#PBS -l select=1:ncpus=1:mpiprocs=1:ngpus=1:mem=2gb
#PBS -l walltime=00:15:00

# When to send a status email ("-m abe" sends e-mails at job abort, begin, and end)
#--PBS -m ae
#--#PBS -M account@niu.edu

PROJECT_DIRECTORY=/home/&lt;your_account_username&gt;/projects/docker/premade_image_gpu
echo "This job's working directory is $PROJECT_DIRECTORY"
cd $PROJECT_DIRECTORY

# Enable linger for the user
echo ""
echo "Enabling linger for the user..."
loginctl enable-linger &lt;your_account_username&gt;
echo "Done!"

# Initialize GPU device files by running our script with CUDA
echo ""
echo "Running a quick CUDA program..."
module purge; module load cuda/cuda-11.8
./initialize_cuda \
    &gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"

# Start the container
# 
# There are five flags, most of which will never change:
# - `-v $PROJECT_DIRECTORY:/home` mounts the project directory to the `/home` 
#    directory in the container.
# - `-w /home` sets the working directory in the container to `/home`.
# - `-t` allocates a pseudo-TTY. This is useful for running the container in
#    the background.
# - `-d` runs the container in the background.
#
# The last argument is the image name. This is the only thing that will change
#  between projects, this is the name of the image we want to run.
# 
# For instance, in this case, `cuda:12.6.0-cudnn-runtime-ubuntu22.04`:
# - `cuda` is the name of the image.
# - `12.6.0-cudnn-runtime-ubuntu22.04` is the tag of the image, which specifies
#    the version of the image, the base operating system, and any additional
#    software that is included in the image.
#
# Millions of pre-built images are available on Docker Hub, and will likely 
#  already have an image that suits your needs! You can search for images here:
#  https://hub.docker.com/
#
# Note: There may be many logs that are printed to the console when the container
#  is started. Despite being error-level, this is normal, and you can ignore them.
echo ""
echo "Starting the container..."
/bin/podman run                                 \
    -v $PROJECT_DIRECTORY:/home                 \
    -w /home                                    \
    --name cuda_container                       \
    --device nvidia.com/gpu=all                 \
    --security-opt=label=disable                \
    -t -d                                       \
    nvidia/cuda:12.6.0-cudnn-devel-ubuntu20.04  \
    #&gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"

# Run our `nvidia-smi` command
#
# The `exec` command runs a command in a running container. In this case, we are
#  running the `nvidia-smi` command in the `cuda_container` container.
# 
# There is a generic error message, which can be ignored.
echo ""
echo "Running the \`nvidia-smi\` command..."
/bin/podman exec cuda_container nvidia-smi
echo "Done!"

# Kill the container
#
# The `kill` command stops a running container. In this case, we are stopping the
#  `cuda_container` container.
echo ""
echo "Stopping the container..."
/bin/podman kill cuda_container \
    &gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"

# Remove the container
#
# The `rm` command removes a container. In this case, we are removing the
#  `cuda_container` container.
echo ""
echo "Removing the container..."
/bin/podman rm cuda_container \
    &gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"
</code></pre>
<p>As always, don't forget to replace occurrences of <code>&lt;your_account_username&gt;</code> with your actual Metis username.</p>
<p>Now, let's discuss what's changed from Chapter 3.1.</p>
<p>Firstly, we ensure CUDA <code>/dev</code> files are created:</p>
<pre><code class="language-bash">...

# Initialize GPU device files by running our script with CUDA
echo ""
echo "Running a quick CUDA program..."
module purge; module load cuda/cuda-11.8
./initialize_cuda \
    &gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!
echo "Done!"

...
</code></pre>
<p>Secondly, we add the flags which make our GPU visible to Podman (Docker), and we use NVIDIA's CUDA base image:</p>
<pre><code class="language-bash">...

# Start the container
# 
# There are five flags, most of which will never change:
# - `-v $PROJECT_DIRECTORY:/home` mounts the project directory to the `/home` 
#    directory in the container.
# - `-w /home` sets the working directory in the container to `/home`.
# - `-t` allocates a pseudo-TTY. This is useful for running the container in
#    the background.
# - `-d` runs the container in the background.
#
# The last argument is the image name. This is the only thing that will change
#  between projects, this is the name of the image we want to run.
# 
# For instance, in this case, `cuda:12.6.0-cudnn-runtime-ubuntu22.04`:
# - `cuda` is the name of the image.
# - `12.6.0-cudnn-runtime-ubuntu22.04` is the tag of the image, which specifies
#    the version of the image, the base operating system, and any additional
#    software that is included in the image.
#
# Millions of pre-built images are available on Docker Hub, and will likely 
#  already have an image that suits your needs! You can search for images here:
#  https://hub.docker.com/
#
# Note: There may be many logs that are printed to the console when the container
#  is started. Despite being error-level, this is normal, and you can ignore them.
/bin/podman run                                 \
    -v $PROJECT_DIRECTORY:/home                 \
    -w /home                                    \
    --name cuda_container                       \
    --device nvidia.com/gpu=all                 \
    --security-opt=label=disable                \
    -t -d                                       \
    nvidia/cuda:12.6.0-cudnn-devel-ubuntu20.04  \
    #&gt; /dev/null 2&gt;&amp;1 # You can remove this line if you want to see the logs!

...
</code></pre>
<p>Third and finally, to test, we run <code>nvidia-smi</code>, which details available NVIDIA GPUS:</p>
<pre><code class="language-bash">...

# Run our `nvidia-smi` command
#
# The `exec` command runs a command in a running container. In this case, we are
#  running the `nvidia-smi` command in the `cuda_container` container.
# 
# There is a generic error message, which can be ignored.
echo ""
echo "Running the \`nvidia-smi\` command..."
/bin/podman exec cuda_container nvidia-smi
echo "Done!"

...
</code></pre>
<p>Finally, it's worth noting that the first execution will take some time - the NVIDIA CUDA image is quite large at ~5GB. To test our PBS job:</p>
<pre><code class="language-bash">$ qsub run.pbs
18731.cm
</code></pre>
<p>After some time (remember, you can check the status of a job with <code>qstat -x &lt;job_id&gt;</code>!):</p>
<pre><code>$ cat premade_image_gpu.o18731
...

Fri Aug 16 21:50:56 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB           On | 00000000:27:00.0 Off |                    0 |
| N/A   38C    P0               40W / 250W|      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+

...
</code></pre>
<h2 id="closing-thoughts-3"><a class="header" href="#closing-thoughts-3">Closing Thoughts</a></h2>
<p>Congratulations! You've officially achieved full GPU passthrough to Podman (Docker) through the PBS job scheduling system!</p>
<p>This is quite the technical feat, and displays some of the most impressive containerization and supercomputing technologies available.</p>
<p>Almost every conceivable project can be run on Metis using this technique, from CUDA-based quantum simulations, to machine learning models, to facial recognition software.</p>
<p>For those whos' projects are complete using this tactic, you can safely stop reading here, if you would like. If SSH automation (<strong>Chapter 4.1</strong>) interests you, you can also safely skip to that chapter.</p>
<p>The next chapter, <strong>Chapter 3.3</strong>, will provide insight into writing your own base images from the ground up, and some tactics for optimizing base images for build-time and size.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="33-creating-your-own-docker-base-images"><a class="header" href="#33-creating-your-own-docker-base-images">3.3. Creating your Own Docker Base Images</a></h1>
<p><em>You can find the code mentioned in this chapter <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/docker/custom_image">in this book's repository</a>!</em></p>
<p>Unlike previous chapters, this will not have an example project, and will instead be more free-form to act as a basepoint for your own research!</p>
<p>We will discuss some possible venues from where to learn Dockerfile syntax, building images, and running them on Metis to create a solution that fits your quota.</p>
<h2 id="goals-4"><a class="header" href="#goals-4">Goals</a></h2>
<ul>
<li>Look at some examples of a <code>Dockerfile</code></li>
<li>Get a rough idea for how to write your own <code>Dockerfile</code></li>
<li>Get a rough idea on resources about publishing yor own Docker Images</li>
</ul>
<h2 id="what-actually-is-a-docker-image"><a class="header" href="#what-actually-is-a-docker-image">What Actually Is a Docker Image?</a></h2>
<p>In the past, we've only used images from the <a href="https://hub.docker.com">Docker Hub</a>. But how are those images created?</p>
<p>Docker Images are defined and built from a <a href="https://docs.docker.com/reference/dockerfile/"><code>Dockerfile</code></a>.</p>
<p>They are somewhat similar in nature to PBS files, but they define a lot more, and allow elevated permissions plus more granular control.</p>
<p>Defined below is a <code>Dockerfile</code> for a Python project, which is thoroughly documented:</p>
<pre><code class="language-bash"># syntax=docker/dockerfile:1

# This specifies the base image to base FROM for the image that will be built.
# 
# In this case, we are using the official Python image from Docker Hub.
#
# The tag `3.12.5-bookworm` specifies the version of the Python image to use.
# The tag `bookworm` is a codename for the version of Debian that the image is based on.
# The tag `3.12.5` is the version of Python that the image has preloaded.
# 
# To find more base images, visit `https://hub.docker.com/`!
FROM python:3.12.5-bookworm

# Create a directory at /app to store the application code inside the image.
WORKDIR /app

# RUN instructions are executed during the build process of the image.
# 
# This means, once the image is built, the following commands will be executed,
#  but not when the container is run. For instance, the following commands will
#  be executed when the image is built, but not when the container is run:
#  - `apt update` (updates the package manager)
#  - `apt install -y cmake build-essential`
#  - `python -m venv .venv` (creates a virtual environment)
#  - `.venv/bin/pip install numpy` (installs the numpy package)
#
# These RUN commands are extremely useful for setting up the environment, particularly
#  for packages like `numpy` that require compilation with `cmake` and `build-essential`.
#
# It's worth noting that the Docker build process is not interactive, so you can't
#  interact with the terminal during the build process. This is why the `-y` flag is
#  used in the `apt install` command to automatically answer "yes" to the prompt!
RUN apt update
RUN apt install -y cmake build-essential

RUN python -m venv .venv
RUN .venv/bin/pip install numpy

# COPY the source code from
#  the host machine (`.`, where the Dockerfile is located)
#  to the image     (`.`, or the working directory).
#
# As specified in the `WORKDIR` instruction above, the working
#  directory is `/app`.
#
# For example, running `docker build ...` from the directory of this project
#  will copy from `/home/user/projects/docker/premade_image/main.py` to `/app/main.py`
#  in the image!
COPY . .

# When the application is built, the container will run the following CMD.
#
# The CMD instruction specifies the command that will be executed when the container
#  is run, but not when the image is built. For instance, the following command will
#  be executed when the container is run:
#  - `.venv/bin/python3 main.py` (runs the `main.py` script)
#
# In this case, the command is `.vent/bin/python3 main.py`, which will run the `main.py` script.
CMD .venv/bin/python3 main.py
</code></pre>
<p><code>Dockerfiles</code> live in the root of a project. An example Python project layout:</p>
<pre><code>src/
- main.py
- Dockerfile
</code></pre>
<p>The reason why <code>Dockerfiles</code> are useful becomes more apparent the more complex and dependency-heavy your project is. Each command in a <code>Dockerfile</code> is cached step-by-step, which means, after the first time the above <code>Dockerfile</code> is built, steps such as dependency installation with <code>apt</code> are not performed again.</p>
<p>This means that builds with <code>Dockerfile</code> are exceptionally fast, if properly optimized!</p>
<p>Linked <a href="https://www.digitalocean.com/community/tutorials/how-to-optimize-docker-images-for-production">here</a> is a fan-favorite crash course in optimizing <code>Dockerfiles</code>.</p>
<h2 id="how-do-i-write-a-dockerfile-from-the-ground-up"><a class="header" href="#how-do-i-write-a-dockerfile-from-the-ground-up">How Do I Write a <code>Dockerfile</code> From the Ground Up?</a></h2>
<p>This varies from project-to-project based on decisions such as:</p>
<ul>
<li>Base operating system</li>
<li>Programming Language</li>
<li>Dependencies</li>
<li>Whether you plan to use CUDA or CUDNN</li>
</ul>
<p>From the get-go, if you plan to use CUDA and/or CUDNN, you should use <a href="https://hub.docker.com/r/nvidia/cuda/">NVIDIA's base images</a> in your <code>FROM</code> instructions. This will save you a ton of time with configuration, as it's much simpler to install a programming language than to install CUDNN or CUDA.</p>
<p>Depending on your project, Docker has wonderful guides linked <a href="https://docs.docker.com/language/">here</a>. These include:</p>
<ul>
<li>Go</li>
<li>Python</li>
<li>R</li>
<li>Rust</li>
</ul>
<p>...and many more.</p>
<p>Once you have written and built your image, you should test it locally on your own machine. In fact, all Docker development is best done on your local machine.</p>
<h2 id="publishing-your-image-to-a-public-registry"><a class="header" href="#publishing-your-image-to-a-public-registry">Publishing your Image to a Public Registry</a></h2>
<p>Now, unfortunately, I have not found a way to build Docker Images on a login node on Metis in a way that allows you to copy the image over to the desired compute node.</p>
<p>The workaround is to build them locally, publish our images, and then pull them onto the compute node.</p>
<h2 id="how-do-i-choose-where-to-publish"><a class="header" href="#how-do-i-choose-where-to-publish">How Do I Choose Where to Publish?</a></h2>
<p>There are two good options for public registries:</p>
<ul>
<li>Docker Hub</li>
<li>GitHub Container Repository (GHCR)</li>
</ul>
<p>If you are not tracking your project with GitHub already, I suggest that you follow <a href="https://www.geeksforgeeks.org/docker-publishing-images-to-docker-hub/">this guide</a> to publish to Docker Hub (what we have used in past chapters).</p>
<p>If you are tracking with GitHub, it may be more convenient to instead use GitHub Actions to automatically build and publish your image with each commit.</p>
<p>GitHub Actions is significantly more ideal, but does build slower. Our team chose to use this route, since our entire codebase is on GitHub! Linked below is documentation on how to do so, and the two repositories we have automatic builds enabled on.</p>
<ul>
<li><a href="https://docs.docker.com/build/ci/github-actions/">GitHub's Documentation</a></li>
<li><a href="https://github.com/igait-niu/igait-openpose"><code>igait-openpose</code></a> (runs on Metis)</li>
<li><a href="https://github.com/igait-niu/igait-backend"><code>igait-backend</code></a> (runs on AWS)</li>
</ul>
<p>With this approach, you can containerize virtually any project with ease.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="4-advanced-metis-usage-techniques"><a class="header" href="#4-advanced-metis-usage-techniques">4. Advanced Metis Usage Techniques</a></h1>
<p>The first and only advanced technique this book will cover with examples is SSH automation.</p>
<p>This allows a Metis user to automate what would otherwise be:</p>
<ul>
<li><strong>1</strong> - Logging into Metis over SSH</li>
<li><strong>2</strong> - Running job submission commands</li>
<li><strong>3</strong> - Retrieving a job ID</li>
</ul>
<p>By doing this, we can intergrate Metis into the workflow of any existing web server!</p>
<p>This technique also opens the door to other techniques, three of which I will briefly mention below. Because of the varied and complex nature of implementation, they will only be described conceptually.</p>
<h3 id="providing-files-to-metis-remotely"><a class="header" href="#providing-files-to-metis-remotely">Providing Files to Metis Remotely</a></h3>
<p>By adding file IDs, download links, or using another way to communicate a download location, you can use the arguments on a job submission request to provide Metis with a way to download files for processing.</p>
<p>This can be accomplished by reading the provided arguments in your PBS script, and using <code>wget</code>, <code>git</code>, <code>curl</code>, Git LFS, or another download tool to then download the files onto Metis and into the PBS job's working directory.</p>
<h3 id="web-server-completion-reporting"><a class="header" href="#web-server-completion-reporting">Web Server Completion Reporting</a></h3>
<p>Since PBS jobs on Metis have the ability to connect to the internet, it's possible to then ping your webserver to let it know it's finished, instead of guessing.</p>
<p>The process can look like:</p>
<ul>
<li>Create a database to track jobs on your webserver</li>
<li>Create a route that allows updating each job entry via HTTP</li>
<li>Create a new job data structure in your database with a unique ID for a job</li>
<li>Pass the unique ID to the SSH automation as an argument when submitting a new job</li>
<li>Recieve and note that argument in your PBS script file</li>
<li>When work in your PBS script file is done, at the very end, send an HTTP request to the updating route</li>
<li>Update the database entry via the route, and handle any interpretation logic for the results of your job</li>
</ul>
<p>This means your server can be aware of the moment your job is complete, and accomplish interpretation results immediately.</p>
<p>Due to the complex and implementation-specific nature of this process, I have not included an example. However, this technique was implemented in our backend for the iGait project, the link to which can be found <a href="https://github.com/igait-niu/igait-backend">here</a>!</p>
<h3 id="event-reporting-websocket"><a class="header" href="#event-reporting-websocket">Event Reporting Websocket</a></h3>
<p>This technique only applies to jobs which are short enough to be tracked throughout the lifecycle of a single websocket connection, but can provide real-time results nonetheless.</p>
<p>The steps are mildly similar to the previous technique:</p>
<ul>
<li>Create an (asynchronus and thread-safe) websocket-compatible route, that when opened, first broadcasts a 'starting' event</li>
<li>Create a route that allows updating each job entry via HTTP</li>
<li>Create a new job data structure in your database with a unique ID for a job</li>
<li>Pass the unique ID to the SSH automation as an argument when submitting a new job</li>
<li>Recieve and note that argument in your PBS script file</li>
<li>At each step, send an HTTP request to the webserver with any events you would like to broadcast</li>
<li>At each invocation on the HTTP route, grab a handle to the websocket the ID corresponds to, and broadcast the information from the HTTP request</li>
<li>When the job provides a completion signal, or when you send a fatal error event from your PBS script, close the websocket</li>
</ul>
<p>This is more effective for jobs that may not have a 'final output', but rather, work in chunks. Two common examples are audio encoding/decoding, or token-by-token output from a machine learning model.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="41-ssh-automation-with-metis"><a class="header" href="#41-ssh-automation-with-metis">4.1. SSH Automation with Metis</a></h1>
<p><em>You can find the code mentioned in this chapter <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/rust">in this book's repository</a>!</em></p>
<p>While Metis is an incredibly powerful tool, it does not provide native tooling to allow for automatic job submission.</p>
<p>One solution is to write our own software which submits the job on our behalf, using SSH-related libraries to open a connection and submit commands!</p>
<h2 id="goals-5"><a class="header" href="#goals-5">Goals</a></h2>
<ul>
<li>Learn how to automate an SSH session and commands</li>
<li>Learn how to add your system as a known host</li>
<li>Understand the importance of hardening your code</li>
</ul>
<h2 id="the-problems-1"><a class="header" href="#the-problems-1">The Problem(s)</a></h2>
<p>First, let's talk about what Metis can and can't do.</p>
<p>There are a few problems with automation on Metis that make it more difficult than a standard server:</p>
<ul>
<li><strong>You cannot host a webserver on Metis</strong></li>
<li><strong>Ports cannot be forwarded</strong></li>
</ul>
<p>This means that one cannot simply host a webserver, which could otherwise recieve requests to start jobs automatically.</p>
<p>So, what can we do?</p>
<h2 id="the-solution-1"><a class="header" href="#the-solution-1">The Solution</a></h2>
<p>When asking why you can't automate something, one of the first questions is to ask <em>"Well, how am I able to do it manually?"</em>.</p>
<p>In this case, we are using SSH to connect, and we are then running <code>qsub</code> to submit our jobs.</p>
<p>Well, can that be done programmatically?</p>
<p>Yes, but it's a little more complicated than doing it by hand.</p>
<h2 id="implementation-1"><a class="header" href="#implementation-1">Implementation</a></h2>
<p>For the sake of this guide, I will be using the <a href="https://www.rust-lang.org/">Rust programming language</a>. This is a programming language that best illustrates potential failure points in a program, forcing you to cover error cases in advance.</p>
<p>SSH has many potential points of failure, so using it can help you to think ahead to cover your bases!</p>
<p>However, you don't need to use Rust, you can just as easily write your connection code in Python, C, or any language that suits your need - as long as you write code that can handle and communicate failure well.</p>
<p>For instance, here is example Rust code to submit a <code>qsub</code> job (if you would like to follow along, please see the repository <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/rust">here</a>!):</p>
<pre><pre class="playground"><code class="language-rust">use openssh::{Session, KnownHosts};

async fn submit_pbs_job (
    username: &amp;str,
    path: &amp;str,
    arguments: Vec&lt;(&amp;str, &amp;str)&gt;
) -&gt; Result&lt;String, String&gt; {
    // Open a multiplexed SSH session
    let session = Session::connect_mux(&amp;format!("{username}@metis.niu.edu"), KnownHosts::Strict).await
        .map_err(|err| format!("Couldn't connect to METIS! Are your credentials correct? Raw error:\n{err}"))?;

    // Build and run the `qsub`` command
    let mut submit_job_command_output = session
        .command("qsub");

    // Build the arguments string
    let stringified_arguments = arguments
        .iter()
        .map(|(key, value)| format!("{key}={value}"))
        .collect::&lt;Vec&lt;String&gt;&gt;()
        .join(",");

    // Append the arguments string to the command, if there are any arguments
    let submit_job_command_output = if stringified_arguments.len() &gt; 0 {
        submit_job_command_output
            .arg("-v")
            .arg(stringified_arguments)
    } else {
        &amp;mut submit_job_command_output
    };

    // Append the job script path to the command
    let submit_job_command_output = submit_job_command_output
        .arg(path)
        .output().await
        .map_err(|err| format!("Failed to run qsub command! Raw error:\n{err}"))?;

    // Check if the command was successful
    if !submit_job_command_output.status.success() {
        let err = String::from_utf8(submit_job_command_output.stderr)
            .map_err(|err| format!("Failed to decode the error message! Raw error:\n{err}"))?;

        return Err(format!("When running the qsub command, the following error occurred:\n{err}"));
    } 

    // Otherwise, return the output (as a string)
    let successful_output = String::from_utf8(submit_job_command_output.stdout)
        .map_err(|err| format!("Failed to decode the output message! Raw error:\n{err}"))?;

    Ok(successful_output)
}

#[tokio::main]
async fn main() {
    // Submit a job to the METIS cluster
    let job_id = submit_pbs_job("z1994244", "/home/z1994244/projects/cpp/hello_world/run.pbs", vec![
        ("ARGUMENT_1", "VALUE_1"),
        ("ARGUMENT_2", "VALUE_2"),
        ("ARGUMENT_3", "VALUE_3"),
    ]).await;

    // Check if the job was submitted successfully
    match job_id {
        Ok(job_id) =&gt; println!("Job submitted successfully! Job ID: {job_id}"),
        Err(err) =&gt; eprintln!("Failed to submit the job! Error message:\n{err}"),
    }
}</code></pre></pre>
<p>Our first step is to use an SSH library - in this case, the crate <code>openssh</code> - to open a <a href="https://en.wikibooks.org/wiki/OpenSSH/Cookbook/Multiplexing">multiplexed</a> SSH connection.</p>
<p>Many other libraries exist for other languages, such as <code>ssh-python</code> for Python and <code>ssh</code> for Go.</p>
<p>However, it's worth noting just how many potential points of failure there are:</p>
<ul>
<li>The SSH can fail to open because there wasn't a known host</li>
<li>The command it can fail to send over SSH</li>
<li>The <code>qsub</code> command can fail (on Metis' end), and return an error</li>
<li>The <code>stderr</code> from reading the failure reason from Metis can provide invalid UTF-8 (unlikely, but possible!)</li>
<li>The output from <code>stdout</code> of the <code>qsub</code> command can provide invalid UTF-8 (unlikely, but possible!)</li>
</ul>
<p>The first failure will likely happen, unless you've aleady made Metis a known host on the system you will be automating SSH from.</p>
<p>So, how do we add Metis as a known host? We need to create an SSH key, and copy it over to Metis. This allows Metis to skip password-based authentication thanks to knowing it's us!</p>
<p>You can hit enter through all of the prompts in the <code>ssh-keygen</code> command, but run the following <strong>on your host machine, not Metis</strong>:</p>
<pre><code>$ ssh-keygen
$ ssh-copy-id &lt;your_account_username&gt;@metis.niu.edu
</code></pre>
<p>Now that Metis is a known host, we can test our program.</p>
<p>If you are following along with this tutorial in Rust, you can find the codebase <a href="https://github.com/hiibolt/niu-metis-documentation/tree/main/projects/rust">here</a>, as you'll need to have the <code>openssh</code> and <code>tokio</code> crates installed and configured.</p>
<p>Testing our program:</p>
<pre><code>$ cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.04s
     Running `target/debug/igait-ssh-testing`
Job submitted successfully! Job ID: 18734.cm
</code></pre>
<p>Congratulations! It worked, and you've just submitted a PBS job automatically!</p>
<h2 id="important-notes"><a class="header" href="#important-notes">Important Notes</a></h2>
<p>Many <code>openssh</code> implementations, including in Rust, only run commands from the home directory. In some implementations, you can change this, but in many, you cannot. This is why, throughout our projects, we've been providing absolute paths. Otherwise, the <code>$PBS_O_WORKDIR</code> for our SSH automation would resolve to <code>~/.</code>, which would cause unexpected failures.</p>
<p>By writing our paths in absolute, we guarantee proper execution.</p>
<p>Now, where is our output? Well, as previously mentioned, often, commands are run from the <code>~/.</code> (home) directory. Sure enough, after manually logging into Metis:</p>
<pre><code>$ ls
bin  examples  hello_world.o18734  projects  rundir
</code></pre>
<p>While not shown here, it is possible to automatically read the contents of this output folder, using a <code>cat</code> command or the likes after the expected run time is over.</p>
<p>It cannot be understated how important it is that you are extremely careful whenever automating your workflow!</p>
<p>You must purify your inputs, and ensure it is physically impossible for an attacker to exploit your backend in any way possible. To not do so would endanger the work of fellow NIU researchers, students and staff.</p>
<p>However, as mentioned in the preface to this chapter, it's an incredibly effective method that can be further evolved into even more effecient and better integrated systems!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="5-conclusion-and-helpful-resources"><a class="header" href="#5-conclusion-and-helpful-resources">5. Conclusion and Helpful Resources</a></h1>
<p>This concludes my documentation for the NIU Metis supercomputing systems.</p>
<p>I genuinely hope this helps you achieve your goals on Metis, as using complex systems such as Metis is often daunting and time-consuming even for the most tenured of Linux users.</p>
<p>Despite being a Linux user, I am a strong believer in 'less time working on preparing to work'. This isn't to say I don't like planning - I use kanban boards for the most basic of tasks - but I do not enjoy spending time troubleshooting. While Linux is a large improvement over Windows for the purpose of development, things are not perfect, and much of a Linux user's time is spent working to get something fixed, rather than working on projects - the problem this guide aims to solve.</p>
<p>I hope this guide helped streamline your getting started on Metis. Below you can find additional resources to help your time on the Metis platform!</p>
<h2 id="helpful-resources"><a class="header" href="#helpful-resources">Helpful Resources</a></h2>
<h3 id="docker-podman-and-nvidia-container-toolkit"><a class="header" href="#docker-podman-and-nvidia-container-toolkit">Docker, Podman, and NVIDIA Container Toolkit</a></h3>
<ul>
<li><a href="https://docs.docker.com/">Docker's Documentation</a></li>
<li><a href="https://docs.podman.io/">Podman's Documentation</a></li>
<li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/index.html">NVIDIA Container Toolkit Documentation</a></li>
</ul>
<h3 id="cuda-and-openmpi"><a class="header" href="#cuda-and-openmpi">CUDA and OpenMPI</a></h3>
<ul>
<li><a href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">NVIDIA's Amazing Introduction to CUDA</a></li>
<li><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications">NVIDIA CUDA Feature Availability</a></li>
<li><a href="https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf">NVIDIA A100 Technical Documentation</a></li>
<li><a href="https://www.openmp.org/wp-content/uploads/omp-hands-on-SC08.pdf">OpenMPI Into-The-Fire Introduction</a></li>
<li><a href="https://docs.open-mpi.org/en/v5.0.x/index.html">OpenMPI Documentation</a></li>
</ul>
<h3 id="pbs-professional"><a class="header" href="#pbs-professional">PBS Professional</a></h3>
<ul>
<li><a href="https://help.altair.com/2024.1.0/PBS%20Professional/PBSProgramGuide2024.1.pdf">PBS Professional Documentation</a></li>
<li><a href="https://www.nas.nasa.gov/hecc/support/kb/Commonly-Used-PBS-Commands_174.html">NASA's PBS Quick Reference</a></li>
<li><a href="https://www.jlab.org/hpc/PBS/qsub.html"><code>qsub</code> Documentation</a></li>
<li><a href="https://www.jlab.org/hpc/PBS/qstat.html"><code>qstat</code> Documentation</a></li>
<li><a href="https://www.jlab.org/hpc/PBS/qdel.html"><code>qdel</code> Documentation</a></li>
</ul>
<h3 id="metis"><a class="header" href="#metis">Metis</a></h3>
<ul>
<li><a href="https://www.niu.edu/crcd/current-users/getting-started/index.shtml">NIU's Official Metis Documentation</a></li>
</ul>
<h2 id="final-notes"><a class="header" href="#final-notes">Final Notes</a></h2>
<p>I am an undergraduate student at NIU, and my GitHub is <a href="https://github.com/hiibolt">@hiibolt</a>. If you find errors or want additional clarification, feel free to open an issue on <a href="https://github.com/hiibolt/niu-metis-documentation">this book's repository</a>, or email me at <code>me@hiibolt.com</code>.</p>
<p>You can find more of my computation writing on my <a href="https://blog.hiibolt.com">blog</a>, on which I have an article about my time with the iGait development team, which I greatly enjoyed!</p>
<p>Thank you so much for taking time out of your day to read my work, and I wish you the best of luck in your academic endeavors.</p>
<p><em>Stay cozy, this is <a href="https://github.com/hiibolt">@hiibolt</a>, signing out :3</em></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
